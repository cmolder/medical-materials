{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_mmaccnn_analysis\n",
    "A notebook to analytically evaluate the training process for the MMAC-CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from datasets import PatchNpyDataset\n",
    "from mmac_net import MMAC_CNN\n",
    "from mmac_net.train_helpers import loss_acc\n",
    "\n",
    "import train_mac as train_mmac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO pass required training parameters to the train_dcnn.train / train_dcnn.validate automatically\n",
    "BATCH_SIZE    = 50\n",
    "LR_PATIENCE   = 1  # Number of epochs of training (validation?) loss increase before the learning rate clamps down\n",
    "EPOCHS        = 15 # Number of epochs to train each model\n",
    "MODEL_SAMPLES = 30 # Sample size of randomly-initialized models to compare\n",
    "DATA_ROOT     = '' # Root path where patch data/etc. is found.\n",
    "VERBOSE       = False # Whether to print detailed output during sampling/training\n",
    "\n",
    "A_path = 'a.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional transforms that normalizes and augment the image patches.\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the material patch datasets\n",
    "# - The testing set is only used to track its loss over time,\n",
    "#   it is not used for parameter tuning / etc.\n",
    "train_set     = PatchNpyDataset(root = os.path.join(DATA_ROOT, 'patch-set', 'npy', 'train'), transform = train_tf)\n",
    "train_loader  = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_losses     = []\n",
    "train_accuracies = []\n",
    "print(f'Training set   : {len(train_set)} samples')\n",
    "\n",
    "val_set     = PatchNpyDataset(root = os.path.join(DATA_ROOT, 'patch-set', 'npy', 'val'), transform = val_tf)\n",
    "val_loader  = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_losses     = []\n",
    "val_accuracies = []\n",
    "print(f'Validation set : {len(val_set)} samples')\n",
    "\n",
    "test_set     = PatchNpyDataset(root = os.path.join(DATA_ROOT, 'patch-set', 'npy', 'test'), transform = val_tf)\n",
    "test_loader  = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_losses     = []\n",
    "test_accuracies = []\n",
    "print(f'Testing set    : {len(test_set)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device     = torch.device(device_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_losses(tr_losses, vl_losses, ts_losses, sample_idx=0):\n",
    "    \"\"\"Plots the training, validation, and testing losses per epoch \n",
    "    for one model sample using Matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "        tr_losses: np.array\n",
    "            Total training loss per epoch.\n",
    "        vl_losses: np.array\n",
    "            Total validation loss per epoch.\n",
    "        ts_losses: np.array\n",
    "            Total testing losses per epoch.\n",
    "        sample_idx: int (optional)\n",
    "            The index of the desired sample. The default is 0.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title('MAC-CNN losses per epoch')\n",
    "    \n",
    "    x = np.arange(0, EPOCHS)\n",
    "    ax.plot(x, tr_losses[sample_idx,:], '.-', label='Training loss', color='blue')\n",
    "    ax.plot(x, vl_losses[sample_idx,:], '.-', label='Validation loss', color='orange')\n",
    "    ax.plot(x, ts_losses[sample_idx,:], '.-', label='Testing loss', color='green')\n",
    "    ax.set_xlim(0)\n",
    "    ax.set_ylim(0)\n",
    "\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Total loss')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.savefig('maccnn-epoch-losses.eps', dpi=192, format='eps')\n",
    "    #plt.savefig('maccnn-epoch-losses.png', dpi=300, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_accuracies(tr_accuracies, vl_accuracies, ts_accuracies, sample_idx=0):\n",
    "    \"\"\"Plots the training, validation, and testing accuracies per epoch \n",
    "    for one model sample using Matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "        tr_accuracies: np.array\n",
    "            Total training acccuracies per epoch.\n",
    "        vl_accuracies: np.array\n",
    "            Total validation accuracies per epoch.\n",
    "        ts_accuracies: np.array\n",
    "            Total testing accuracies per epoch.\n",
    "        sample_idx: int (optional)\n",
    "            The index of the desired sample. The default is 0.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title('MAC-CNN accuracies per epoch')\n",
    "    \n",
    "    x = np.arange(0, EPOCHS)\n",
    "    ax.plot(x, tr_accuracies[sample_idx,:], '.-', label='Training accuracy', color='blue')\n",
    "    ax.plot(x, vl_accuracies[sample_idx,:], '.-', label='Validation accuracy', color='orange')\n",
    "    ax.plot(x, ts_accuracies[sample_idx,:], '.-', label='Testing accuracy', color='green')\n",
    "    \n",
    "    ax.set_xlim(xmin=0)\n",
    "    ax.set_ylim(ymin=0, ymax=100)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.savefig('maccnn-epoch-accuracies.eps', dpi=192, format='eps')\n",
    "    #plt.savefig('mmaccnn-epoch-accuracies.png', dpi=300, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_losses(tr_losses, vl_losses, ts_losses):\n",
    "    \"\"\"Plots the distributions of training, validation, and testing\n",
    "    losses per epoch for all model samples using Matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "        tr_losses: np.array\n",
    "            Total training loss per epoch.\n",
    "        vl_losses: np.array\n",
    "            Total validation loss per epoch.\n",
    "        ts_losses: np.array\n",
    "            Total testing losses per epoch.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title('MAC-CNN losses per epoch')\n",
    "    \n",
    "    # Build median lines\n",
    "    med_tr_losses = np.median(tr_losses, axis=0)\n",
    "    med_vl_losses = np.median(vl_losses, axis=0)\n",
    "    med_ts_losses = np.median(ts_losses, axis=0)\n",
    "    \n",
    "    # Build 75th percentile lines\n",
    "    p75_tr_losses = np.percentile(tr_losses, 75, axis=0)\n",
    "    p75_vl_losses = np.percentile(vl_losses, 75, axis=0)\n",
    "    #p75_ts_losses = np.percentile(ts_losses, 75, axis=0)\n",
    "    \n",
    "    # Build 25th percentile lines\n",
    "    p25_tr_losses = np.percentile(tr_losses, 25, axis=0)\n",
    "    p25_vl_losses = np.percentile(vl_losses, 25, axis=0)\n",
    "    #p25_ts_losses = np.percentile(ts_losses, 25, axis=0)\n",
    "    \n",
    "    x = np.arange(0, EPOCHS)\n",
    "\n",
    "    # Plot median lines\n",
    "    ax.plot(x, med_tr_losses, '.-', label='Training loss', color='blue')\n",
    "    ax.plot(x, med_vl_losses, '.-', label='Validation loss', color='orange')\n",
    "    #ax.plot(x, med_ts_losses, '.-', label='Testing loss', color='green')\n",
    "    \n",
    "    # Plot 25th-75th percentile shaded regions\n",
    "    ax.fill_between(x, p25_tr_losses, p75_tr_losses, facecolor='blue', alpha=0.2)\n",
    "    ax.fill_between(x, p25_vl_losses, p75_vl_losses, facecolor='orange',  alpha=0.2)\n",
    "    #ax.fill_between(x, p25_ts_losses, p75_ts_losses, facecolor='green', alpha=0.2)\n",
    "    \n",
    "    ax.set_xlim(0)\n",
    "    ax.set_ylim(0)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Total loss')\n",
    "    ax.legend()\n",
    "    \n",
    "    #plt.savefig('mmaccnn-epoch-losses-dist.eps', dpi=192, format='eps')\n",
    "    plt.savefig('maccnn-epoch-losses-dist.png', dpi=192, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_accuracies(tr_accuracies, vl_accuracies, ts_accuracies):\n",
    "    \"\"\"Plots the distributions of training, validation, and testing \n",
    "    accuracies per epoch for all model samples using Matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "        tr_accuracies: np.array\n",
    "            Total training acccuracies per epoch.\n",
    "        vl_accuracies: np.array\n",
    "            Total validation accuracies per epoch.\n",
    "        ts_accuracies: np.array\n",
    "            Total testing accuracies per epoch.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title('MAC-CNN accuracies per epoch')\n",
    "       \n",
    "    # Build median lines\n",
    "    med_tr_accuracies = np.median(tr_accuracies, axis=0)\n",
    "    med_vl_accuracies = np.median(vl_accuracies, axis=0)\n",
    "    med_ts_accuracies = np.median(ts_accuracies, axis=0)\n",
    "    \n",
    "    # Build 75th %ile lines\n",
    "    p75_tr_accuracies = np.percentile(tr_accuracies, 75, axis=0)\n",
    "    p75_vl_accuracies = np.percentile(vl_accuracies, 75, axis=0)\n",
    "    p75_ts_accuracies = np.percentile(ts_accuracies, 75, axis=0)\n",
    "    \n",
    "    # Build 25th %ile lines\n",
    "    p25_tr_accuracies = np.percentile(tr_accuracies, 25, axis=0)\n",
    "    p25_vl_accuracies = np.percentile(vl_accuracies, 25, axis=0)\n",
    "    p25_ts_accuracies = np.percentile(ts_accuracies, 25, axis=0)\n",
    "    \n",
    "    x = np.arange(0, EPOCHS)\n",
    "\n",
    "    # Plot median lines\n",
    "    ax.plot(x, med_tr_accuracies, '.-', label='Training accuracy', color='blue')\n",
    "    ax.plot(x, med_vl_accuracies, '.-', label='Validation accuracy', color='orange')\n",
    "    #ax.plot(x, med_ts_accuracies, '.-', label='Testing loss', color='green')\n",
    "    \n",
    "    # Plot 25th-75th percentile shaded regions\n",
    "    ax.fill_between(x, p25_tr_accuracies, p75_tr_accuracies, facecolor='blue', alpha=0.2)\n",
    "    ax.fill_between(x, p25_vl_accuracies, p75_vl_accuracies, facecolor='orange', alpha=0.2)\n",
    "    #ax.fill_between(x, p25_ts_accuracies, p75_ts_accuracies, facecolor='green', alpha=0.2)\n",
    "    \n",
    "    ax.set_xlim(xmin=0)\n",
    "    ax.set_ylim(ymin=0, ymax=100)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.legend()\n",
    "    \n",
    "    #plt.savefig('mmaccnn-epoch-accuracies-dist.eps', dpi=192, format='eps')\n",
    "    plt.savefig('maccnn-epoch-accuracies-dist.png', dpi=192, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, loader, w_per = 1e0, w_kld = 1e-2, verbose=True):\n",
    "    \"\"\"Tests the MMAC-CNN.\n",
    "    \n",
    "    Parameters:\n",
    "        model: torch.nn\n",
    "            The neural network being tested.\n",
    "        device: string\n",
    "            The device (cpu or cuda) that the model is being run on.\n",
    "        test_loader: Dataloader\n",
    "            The test data.\n",
    "        verbose: bool (optional)\n",
    "            If True, prints out information (in addition to progress \n",
    "            bars) from the function.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    A = model.A\n",
    "    total_loss  = 0.0\n",
    "    total_acc   = 0.0\n",
    "    total_ucost = 0.0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(tqdm(test_loader, unit=' testing batches')):\n",
    "        X, y = batch\n",
    "\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        # y_pred is the k class prediction\n",
    "        # A_preds are the a1, a2, ..., a5, a_final m attribute predictions\n",
    "        # from each level of the ResNet auxillary layers\n",
    "        y_pred, A_preds = model(X)   \n",
    "        loss, acc, u_cost = loss_acc(y, y_pred, A, A_preds, w_kld, w_per)\n",
    "        \n",
    "        total_loss  += float(loss)\n",
    "        total_acc   += float(acc)\n",
    "        total_ucost += float(u_cost)\n",
    "\n",
    "    # Print results\n",
    "    if verbose:\n",
    "        print(f'Test loss  : {test_loss / len(loader)}')\n",
    "        print(f'Test ucost : {test_ucost / len(loader)}')\n",
    "        print(f'Test acc   : {test_acc / len(loader) * 100:.3f}%')\n",
    "    \n",
    "    return total_loss, total_acc / len(loader), total_ucost / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Labels   : {train_set.get_labels()}')\n",
    "print(f'Device   : {device_str}')\n",
    "print(f'Verbose? : {VERBOSE}')\n",
    "\n",
    "train_losses = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "val_losses   = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "test_losses  = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "\n",
    "train_accuracies = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "val_accuracies   = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "test_accuracies  = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "\n",
    "train_ucosts = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "val_ucosts   = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "test_ucosts  = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "\n",
    "min_loss = float('inf')    # Lowest loss of the D-CNN on the validation set of all epochs (and model samples) so far\n",
    "A        = np.load(A_path) # A matrix for the constrained linear layers\n",
    "\n",
    "for s in range(MODEL_SAMPLES):\n",
    "    print(f'\\n---------------- SAMPLE {s+1}/{MODEL_SAMPLES} ---------------- ')\n",
    "    \n",
    "    mmac_cnn  = MMAC_CNN(A, 32).to(device) # Create a new model sample (Second parameter assumes the image patches are 32x32 px)\n",
    "    optimizer = optim.Adam(mmac_cnn.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=LR_PATIENCE, min_lr=1e-8)\n",
    "    \n",
    "    for e in range(EPOCHS):\n",
    "        print(f'~~~~ EPOCH {e+1}/{EPOCHS} ~~~~')\n",
    "        print(f'lr: {optimizer.param_groups[0][\"lr\"]}')\n",
    "\n",
    "        train_loss, acc, ucost = train_mmac.train(\n",
    "            mmac_cnn, device, train_loader, optimizer, \n",
    "            verbose=VERBOSE\n",
    "        )\n",
    "        \n",
    "        train_losses[s, e]     = train_loss\n",
    "        train_accuracies[s, e] = acc * 100.0\n",
    "        train_ucosts[s, e]     = ucost\n",
    "\n",
    "        val_loss, acc, ucost = train_mmac.validate(\n",
    "            mmac_cnn, device, val_loader, verbose=VERBOSE\n",
    "        )\n",
    "        \n",
    "        val_losses[s, e]     = val_loss\n",
    "        val_accuracies[s, e] = acc * 100.0\n",
    "        val_ucosts[s, e]     = ucost\n",
    "\n",
    "        if s == 0:\n",
    "            # Only run the testing set of the first sample, to show how extremely close\n",
    "            # testing and validation loss are.\n",
    "            test_loss, acc, ucost = test(\n",
    "                mmac_cnn, device, test_loader, verbose=VERBOSE\n",
    "            )\n",
    "            \n",
    "            test_losses[s, e]     = test_loss\n",
    "            test_accuracies[s, e] = acc * 100.0\n",
    "            test_ucosts[s, e]     = ucost\n",
    "\n",
    "        # If this is the lowest-loss (and therefore generally most accurate)\n",
    "        # run so far out of ALL model samples, save the MMAC-CNN model weights to disk\n",
    "        if (val_loss < min_loss):\n",
    "            min_loss = val_loss\n",
    "            print('New minimum validation loss:', min_loss)\n",
    "            print('Saving mmac_cnn state to mmac_cnn.pt...')\n",
    "            torch.save(mmac_cnn, 'mmac_cnn.pt')      \n",
    "        scheduler.step(val_loss)\n",
    "    \n",
    "    # Free CUDA memory\n",
    "    del mmac_cnn\n",
    "    del optimizer\n",
    "    del scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After done, plot the training and testing losses for the first sample (idx 0) on MatPlotLib\n",
    "plot_sample_losses(train_losses, val_losses, test_losses, sample_idx=0)\n",
    "plot_sample_accuracies(train_accuracies, val_accuracies, test_accuracies, sample_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution_losses(train_losses, val_losses, test_losses)\n",
    "plot_distribution_accuracies(train_accuracies, val_accuracies, test_accuracies)\n",
    "\n",
    "print('Train losses:\\n', train_losses)\n",
    "print('\\nVal losses:\\n', val_losses)\n",
    "\n",
    "print('Train accuracies:\\n', train_accuracies)\n",
    "print('\\nVal accuracies:\\n', val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mmaccnn_train_losses.npy', train_losses)\n",
    "np.save('mmaccnn_val_losses.npy', val_losses)\n",
    "np.save('mmaccnn_test_losses.npy', test_losses)\n",
    "\n",
    "np.save('mmaccnn_train_accuracies.npy', train_accuracies)\n",
    "np.save('mmaccnn_val_accuracies.npy', val_accuracies)\n",
    "np.save('mmaccnn_test_accuracies.npy', test_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medmats",
   "language": "python",
   "name": "medmats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
