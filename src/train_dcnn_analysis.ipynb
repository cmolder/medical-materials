{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_dcnn_analysis\n",
    "A notebook to analytically evaluate the training process for the D-CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import PatchNpyDataset, PatchCompare\n",
    "from d_net import D_CNN\n",
    "\n",
    "import train_dcnn\n",
    "import test_dcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO pass required training parameters to the train_dcnn.train / train_dcnn.validate automatically\n",
    "BATCH_SIZE    = 50\n",
    "EPOCHS        = 15 # Number of epochs to train each model\n",
    "MODEL_SAMPLES = 30 # Sample size of randomly-initialized models to compare\n",
    "DATA_ROOT     = '' # Root path where patch data/etc. is found.\n",
    "VERBOSE = False    # Whether to print detailed output during sampling/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional transforms that normalizes the image for ResNet.\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_tf = transforms.Compose([\n",
    "])\n",
    "\n",
    "# Load the material patch datasets\n",
    "# - The testing set is only used to track its loss over time,\n",
    "#   it is not used for parameter tuning / etc.\n",
    "train_set     = PatchNpyDataset(root = os.path.join(DATA_ROOT, 'patch-set', 'npy', 'train'), transform = train_tf)\n",
    "train_samples = PatchCompare(train_set)\n",
    "train_loader  = DataLoader(train_samples, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_losses  = []\n",
    "train_accuracies = []\n",
    "print(f'Training set   : {len(train_samples)} samples')\n",
    "\n",
    "val_set     = PatchNpyDataset(root = os.path.join(DATA_ROOT, 'patch-set', 'npy', 'val'), transform = val_tf)\n",
    "val_samples = PatchCompare(val_set)\n",
    "val_loader  = DataLoader(val_samples, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_losses  = []\n",
    "val_accuracies = []\n",
    "print(f'Validation set : {len(val_samples)} samples')\n",
    "\n",
    "test_set     = PatchNpyDataset(root = os.path.join(DATA_ROOT, 'patch-set', 'npy', 'test'), transform = val_tf)\n",
    "test_samples = PatchCompare(test_set)\n",
    "test_loader  = DataLoader(test_samples, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_losses  = []\n",
    "test_accuracies = []\n",
    "print(f'Testing set    : {len(test_samples)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device     = torch.device(device_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_losses(tr_losses, vl_losses, ts_losses, sample_idx=0):\n",
    "    \"\"\"Plots the training, validation, and testing losses per epoch \n",
    "    for one model sample using Matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "        tr_losses: np.array\n",
    "            Total training loss per epoch.\n",
    "        vl_losses: np.array\n",
    "            Total validation loss per epoch.\n",
    "        ts_losses: np.array\n",
    "            Total testing losses per epoch.\n",
    "        sample_idx: int (optional)\n",
    "            The index of the desired sample. The default is 0.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title('D-CNN losses per epoch')\n",
    "    \n",
    "    x = np.arange(0, EPOCHS)\n",
    "    ax.plot(x, tr_losses[sample_idx,:], '.-', label='Training loss', color='blue')\n",
    "    ax.plot(x, vl_losses[sample_idx,:], '.-', label='Validation loss', color='orange')\n",
    "    ax.plot(x, ts_losses[sample_idx,:], '.-', label='Testing loss', color='green')\n",
    "    ax.set_xlim(0)\n",
    "    ax.set_ylim(0)\n",
    "\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Total loss')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.savefig('dcnn-epoch-losses.eps', dpi=192, format='eps')\n",
    "    plt.savefig('dcnn-epoch-losses.png', dpi=300, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_accuracies(tr_accuracies, vl_accuracies, ts_accuracies, sample_idx=0):\n",
    "    \"\"\"Plots the training, validation, and testing accuracies per epoch \n",
    "    for one model sample using Matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "        tr_accuracies: np.array\n",
    "            Total training acccuracies per epoch.\n",
    "        vl_accuracies: np.array\n",
    "            Total validation accuracies per epoch.\n",
    "        ts_accuracies: np.array\n",
    "            Total testing accuracies per epoch.\n",
    "        sample_idx: int (optional)\n",
    "            The index of the desired sample. The default is 0.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title('D-CNN accuracies per epoch')\n",
    "    \n",
    "    x = np.arange(0, EPOCHS)\n",
    "    ax.plot(x, tr_accuracies[sample_idx,:], '.-', label='Training accuracy', color='blue')\n",
    "    ax.plot(x, vl_accuracies[sample_idx,:], '.-', label='Validation accuracy', color='orange')\n",
    "    ax.plot(x, ts_accuracies[sample_idx,:], '.-', label='Testing accuracy', color='green')\n",
    "    \n",
    "    ax.set_xlim(xmin=0)\n",
    "    ax.set_ylim(ymin=0, ymax=100)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.savefig('dcnn-epoch-accuracies.eps', dpi=192, format='eps')\n",
    "    plt.savefig('dcnn-epoch-accuracies.png', dpi=300, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_losses(tr_losses, vl_losses, ts_losses):\n",
    "    \"\"\"Plots the distributions of training, validation, and testing\n",
    "    losses per epoch for all model samples using Matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "        tr_losses: np.array\n",
    "            Total training loss per epoch.\n",
    "        vl_losses: np.array\n",
    "            Total validation loss per epoch.\n",
    "        ts_losses: np.array\n",
    "            Total testing losses per epoch.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title('D-CNN losses per epoch')\n",
    "    \n",
    "    # Build median lines\n",
    "    med_tr_losses = np.median(tr_losses, axis=0)\n",
    "    med_vl_losses = np.median(vl_losses, axis=0)\n",
    "    med_ts_losses = np.median(ts_losses, axis=0)\n",
    "    \n",
    "    # Build 75th percentile lines\n",
    "    p75_tr_losses = np.percentile(tr_losses, 75, axis=0)\n",
    "    p75_vl_losses = np.percentile(vl_losses, 75, axis=0)\n",
    "    #p75_ts_losses = np.percentile(ts_losses, 75, axis=0)\n",
    "    \n",
    "    # Build 25th percentile lines\n",
    "    p25_tr_losses = np.percentile(tr_losses, 25, axis=0)\n",
    "    p25_vl_losses = np.percentile(vl_losses, 25, axis=0)\n",
    "    #p25_ts_losses = np.percentile(ts_losses, 25, axis=0)\n",
    "    \n",
    "    x = np.arange(0, EPOCHS)\n",
    "\n",
    "    # Plot median lines\n",
    "    ax.plot(x, med_tr_losses, '.-', label='Training loss', color='blue')\n",
    "    ax.plot(x, med_vl_losses, '.-', label='Validation loss', color='orange')\n",
    "    #ax.plot(x, med_ts_losses, '.-', label='Testing loss', color='green')\n",
    "    \n",
    "    # Plot 25th-75th percentile shaded regions\n",
    "    ax.fill_between(x, p25_tr_losses, p75_tr_losses, facecolor='blue', alpha=0.2)\n",
    "    ax.fill_between(x, p25_vl_losses, p75_vl_losses, facecolor='orange',  alpha=0.2)\n",
    "    #ax.fill_between(x, p25_ts_losses, p75_ts_losses, facecolor='green', alpha=0.2)\n",
    "    \n",
    "    ax.set_xlim(0)\n",
    "    ax.set_ylim(0)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Total loss')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.savefig('dcnn-epoch-losses-dist.eps', dpi=192, format='eps')\n",
    "    plt.savefig('dcnn-epoch-losses-dist.png', dpi=192, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_accuracies(tr_accuracies, vl_accuracies, ts_accuracies):\n",
    "    \"\"\"Plots the distributions of training, validation, and testing \n",
    "    accuracies per epoch for all model samples using Matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "        tr_accuracies: np.array\n",
    "            Total training acccuracies per epoch.\n",
    "        vl_accuracies: np.array\n",
    "            Total validation accuracies per epoch.\n",
    "        ts_accuracies: np.array\n",
    "            Total testing accuracies per epoch.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title('D-CNN accuracies per epoch')\n",
    "       \n",
    "    # Build median lines\n",
    "    med_tr_accuracies = np.median(tr_accuracies, axis=0)\n",
    "    med_vl_accuracies = np.median(vl_accuracies, axis=0)\n",
    "    med_ts_accuracies = np.median(ts_accuracies, axis=0)\n",
    "    \n",
    "    # Build 75th %ile lines\n",
    "    p75_tr_accuracies = np.percentile(tr_accuracies, 75, axis=0)\n",
    "    p75_vl_accuracies = np.percentile(vl_accuracies, 75, axis=0)\n",
    "    p75_ts_accuracies = np.percentile(ts_accuracies, 75, axis=0)\n",
    "    \n",
    "    # Build 25th %ile lines\n",
    "    p25_tr_accuracies = np.percentile(tr_accuracies, 25, axis=0)\n",
    "    p25_vl_accuracies = np.percentile(vl_accuracies, 25, axis=0)\n",
    "    p25_ts_accuracies = np.percentile(ts_accuracies, 25, axis=0)\n",
    "    \n",
    "    x = np.arange(0, EPOCHS)\n",
    "\n",
    "    # Plot median lines\n",
    "    ax.plot(x, med_tr_accuracies, '.-', label='Training accuracy', color='blue')\n",
    "    ax.plot(x, med_vl_accuracies, '.-', label='Validation accuracy', color='orange')\n",
    "    #ax.plot(x, med_ts_accuracies, '.-', label='Testing loss', color='green')\n",
    "    \n",
    "    # Plot 25th-75th percentile shaded regions\n",
    "    ax.fill_between(x, p25_tr_accuracies, p75_tr_accuracies, facecolor='blue', alpha=0.2)\n",
    "    ax.fill_between(x, p25_vl_accuracies, p75_vl_accuracies, facecolor='orange', alpha=0.2)\n",
    "    #ax.fill_between(x, p25_ts_accuracies, p75_ts_accuracies, facecolor='green', alpha=0.2)\n",
    "    \n",
    "    ax.set_xlim(xmin=0)\n",
    "    ax.set_ylim(ymin=0, ymax=100)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.savefig('dcnn-epoch-accuracies-dist.eps', dpi=192, format='eps')\n",
    "    plt.savefig('dcnn-epoch-accuracies-dist.png', dpi=192, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, num_classes, verbose=True):\n",
    "    \"\"\"Runs the testing set on the D-CNN.\n",
    "\n",
    "    Parameters:\n",
    "        model: D_CNN\n",
    "            The D-CNN neural network instance being validated.\n",
    "        device: string\n",
    "            The device (cpu or cuda) that the model is being run on.\n",
    "        test_loader: DataLoader\n",
    "            The testing data.\n",
    "        num_classes: int\n",
    "            The number of material classes\n",
    "            \n",
    "    Returns:\n",
    "        total_loss: float\n",
    "            The total loss accured while evaluating the D-CNN on the validation set.\n",
    "        accuracy: float\n",
    "            The ratio of correct similarity predictions out of all predictions.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct   = 0\n",
    "    incorrect = 0\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Used to generate the D matrix for the DCNN.\n",
    "    Ref_ICs = [] # [# image sets]              List that holds the image class of each ref image viewed\n",
    "    Sim_Ds  = [] # [# image sets, num_classes] List of arrays of binary simiarlity decisions for each ref image\n",
    "                 #                             against the comparsion images                                            \n",
    "    \n",
    "    for batch_idx, batch in enumerate(tqdm(test_loader, unit=' testing batches')):   \n",
    "        images     = batch[0].to(device) # Images\n",
    "        img_labels = batch[1].to(device) # Image labels\n",
    "        cmp_labels = batch[2].to(device) # Comparison labels\n",
    "        results = model(images)\n",
    "        \n",
    "        # Split all of the batch values into tuples of each of the (n + 1) images.\n",
    "        results = torch.split(results, 1, dim=1)\n",
    "        results = [res.squeeze() for res in results]\n",
    "        \n",
    "        cmp_labels = torch.split(cmp_labels, 1, dim=1)\n",
    "        cmp_labels = [lbl.squeeze() for lbl in cmp_labels]\n",
    "        cmp_labels = [lbl.type(torch.LongTensor).to(device) for lbl in cmp_labels]\n",
    "        \n",
    "        img_labels = torch.split(img_labels, 1, dim=1)\n",
    "        img_labels = [lbl.squeeze() for lbl in img_labels]\n",
    "        img_labels = [lbl.type(torch.LongTensor) for lbl in img_labels]\n",
    "\n",
    "        losses = []\n",
    "        for i in range(1, len(results)): # TODO Check why indexes start at 1.  \n",
    "            losses.append(F.cross_entropy(results[i], cmp_labels[i]))\n",
    "            \n",
    "        loss = sum(losses)\n",
    "        total_loss += float(loss)\n",
    "    \n",
    "        # Count the correct/incorrect similarity decisions for this batch\n",
    "        for i in range(len(img_labels[0])):         \n",
    "            for j in range(1, len(cmp_labels)):\n",
    "                comp_cmp_lbl = cmp_labels[j][i].item()\n",
    "                pred = torch.argmax(results[j][i]).item()\n",
    "                is_correct = (pred == comp_cmp_lbl)\n",
    "                if is_correct:\n",
    "                    correct += 1\n",
    "                else:\n",
    "                    incorrect += 1\n",
    "            \n",
    "    accuracy = correct/(correct+incorrect) \n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Testing set : {correct:5}/{correct+incorrect:5}, {accuracy*100:.2f}%')\n",
    "        print(f'Testing loss: {total_loss}')\n",
    "    \n",
    "    del cmp_labels # Free CUDA memory\n",
    "    del img_labels\n",
    "    del results\n",
    "    \n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Labels   : {train_set.get_labels()}')\n",
    "print(f'Device   : {device_str}')\n",
    "print(f'Verbose? : {VERBOSE}')\n",
    "\n",
    "train_losses = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "val_losses   = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "test_losses  = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "\n",
    "train_accuracies = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "val_accuracies   = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "test_accuracies  = np.zeros((MODEL_SAMPLES, EPOCHS))\n",
    "\n",
    "min_loss = float('inf') # Lowest loss of the D-CNN on the validation set of all epochs (and model samples) so far\n",
    "\n",
    "for s in range(MODEL_SAMPLES):\n",
    "    print(f'\\n---------------- SAMPLE {s+1}/{MODEL_SAMPLES} ---------------- ')\n",
    "    \n",
    "    d_cnn     = D_CNN().to(device) # Create a new model sample\n",
    "    optimizer = optim.Adam(d_cnn.parameters(), lr=1e-3)\n",
    "    \n",
    "    for e in range(EPOCHS):\n",
    "        print(f'~~~~ EPOCH {e+1}/{EPOCHS} ~~~~')\n",
    "\n",
    "        train_loss, acc = train_dcnn.train(\n",
    "            d_cnn, device, train_loader, optimizer, \n",
    "            verbose=VERBOSE\n",
    "        )\n",
    "        \n",
    "        train_losses[s, e] = train_loss\n",
    "        train_accuracies[s, e] = acc * 100.0\n",
    "\n",
    "        D, val_loss, acc, model_state = train_dcnn.validate(\n",
    "            d_cnn, device, val_loader, len(val_samples.classes), \n",
    "            verbose=VERBOSE\n",
    "        )\n",
    "        \n",
    "        val_losses[s, e] = val_loss\n",
    "        val_accuracies[s, e] = acc * 100.0\n",
    "\n",
    "        if s == 0:\n",
    "            # Only run the testing set of the first sample, to show how extremely close\n",
    "            # testing and validation loss are.\n",
    "            test_loss, acc = test(\n",
    "                d_cnn, device, test_loader, len(test_samples.classes), \n",
    "                verbose=VERBOSE\n",
    "            )\n",
    "            \n",
    "            test_losses[s, e] = test_loss\n",
    "            test_accuracies[s, e] = acc * 100.0\n",
    "\n",
    "        # If this is the lowest-loss (and therefore generally most accurate)\n",
    "        # run so far out of ALL model samples, save the D matrix and model weights to disk\n",
    "        if val_loss < min_loss:\n",
    "            min_loss = val_loss\n",
    "            print('New minimum validation loss:', min_loss)\n",
    "            print('Saving model to dcnn.pt...')\n",
    "            torch.save(model_state, 'dcnn.pt')\n",
    "            print('Saving D matrix to d.npy...\\n')\n",
    "            np.save('d.npy', D)\n",
    "    \n",
    "    # Free CUDA memory\n",
    "    del d_cnn\n",
    "    del optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After done, plot the training and testing losses for the first sample (idx 0) on MatPlotLib\n",
    "plot_sample_losses(train_losses, val_losses, test_losses, sample_idx=0)\n",
    "plot_sample_accuracies(train_accuracies, val_accuracies, test_accuracies, sample_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution_losses(train_losses, val_losses, test_losses)\n",
    "plot_distribution_accuracies(train_accuracies, val_accuracies, test_accuracies)\n",
    "\n",
    "print('Train losses:\\n',train_losses)\n",
    "print('\\nVal losses:\\n',val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dcnn_train_losses.npy', train_losses)\n",
    "np.save('dcnn_val_losses.npy', val_losses)\n",
    "np.save('dcnn_test_losses.npy', test_losses)\n",
    "\n",
    "np.save('dcnn_train_accuracies.npy', train_accuracies)\n",
    "np.save('dcnn_val_accuracies.npy', val_accuracies)\n",
    "np.save('dcnn_test_accuracies.npy', test_accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medmats",
   "language": "python",
   "name": "medmats"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
