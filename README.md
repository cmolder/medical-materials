# Learning Medical Materials from Radiography Images
This is the source code for the implementation of "Learning Medical Materials from Radiography Images" (Molder, Lowe, and Zhan). This code serves as a deep learning framework for learning materials in medical radiography images like X-rays and MRIs.



## Usage

To run our implementation, we provide a Linux-based [Anaconda](https://www.anaconda.com/) environment. If Anaconda is installed, our environment can be imported by running the following command in the root directory of the repository:

`conda env create --file environment_linux.yml`

### Generating image patches

Our code is able to take in `.dcm` and `.mat` images, either with or without segmentation masks, and process them to generate a set of material
image patches. The script `load_all.py` can be edited to load any medical image dataset that is one of these two formats. Additionally, the names
of the categories generated from each dataset, as well as whether to consider masks, can also be edited. If the file structure of the dataset is
different than the ones we used, the loader files `DcmLoader.py` and `MatLoader.py` can be edited for `.dcm` and `.mat` image datasets respectively.

After loading the desired datasets, `load_all` generates a certain amount of material patches from each dataset based on the parameters selected
in the script. These are then saved to the specfied data path in the following format:

`python load_all.py <data_root>`
- Patch set: `<data_root>/patch-set`
    - `.png` patches: `<data_root>/patch-set/png/{test, train, val}`
    - `.npy` patches: `<data_root>/patch-set/npy/{test, train, val}`


### Training and evaluating D-CNN

The script `train_dcnn.py` allows for training the D-CNN. Simply run the script as follows:

`python train_dcnn.py <data_root>`

The script will expect the image patches to be found in the same structure as generated by `load_all.py`. There are several parameters that can be
tuned within the script as well, like the number of epochs, batch size, and learning rate. As the program trains the D-CNN, it will save the lowest-loss
D-CNN model (`dcnn.pt`) as well as its associated D matrix (`d.npy`) in the current working directory.

A trained D-CNN model can also be tested by running `test_dcnn.py`, as follows:

`python test_dcnn.py <data_root>`

The D-CNN model (`dcnn.pt`) is expected to be located in the current working directory. Like `train_dcnn.py`, this script expects the testing dataset to be in the same directory as generated by `load_all.py`.

### Generating A matrix

The script `test_agen.py` will automatically load `d.npy` in the current working directory, and generate the material attribute-category matrix A using
the L-BFGS-B optimization algorithm. The script only does this one time, and sometimes the resulting distance metric `d(D, A)` may be large. If this is the case,
running it several times and keeping one with a reasonably low distance should work.

The script will save `a.npy` to the current working directory once it is complete. The scripts for training and evaluating the MAC-CNN will expect `a.npy` to be in the current working directory.

### Training and evaluating MAC-CNN

Currently, although we have the code defining the MAC-CNN available, some functions that we used to implement and train the network are not available 
to share with the public at this time. We are currently working to acquire permission from the original authors of this code so that we can share our
modified versions publicly.


## Acknowledgements

We thank Hadi Salman and Alycia Carey for their assistance in helping us develop our approach. We also thank Gabriel Schwartz for providing source code that we referred to during the implementation of this paper. Additionally, we thank the University of Arkansas Honors College for their support, as this research was funded by a University of Arkansas Honors College Team Grant.

### Data acknowledgements
In our paper, we used the following datasets to generate medical texture patches and evaluate D-CNN and MAC-CNN:

#### Brain / tumor datasets
<details closed>
<summary>Brain-Tumor-Progression, The Cancer Imaging Archive</summary>

[Link to dataset](https://wiki.cancerimagingarchive.net/display/Public/Brain-Tumor-Progression)

> Schmainda KM, Prah M (2018). **Data from Brain-Tumor-Progression.** The Cancer Imaging Archive. http://doi.org/10.7937/K9/TCIA.2018.15quzvnb 

> Clark K, Vendt B, Smith K, Freymann J, Kirby J, Koppel P, Moore S, Phillips S, Maffitt D, Pringle M, Tarbox L, Prior F. **The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository**, Journal of Digital Imaging, Volume 26, Number 6, December, 2013, pp 1045-1057. (paper)
</details>

<details closed>
<summary>Brain Tumor Dataset, FigShare</summary>

[Link to dataset](https://search.datacite.org/works/10.6084/M9.FIGSHARE.1512427.V5)

> Cheng, Jun (2017). **brain tumor dataset.** figshare. Dataset. https://doi.org/10.6084/m9.figshare.1512427.v5
</details>

#### Bone datasets
<details closed>
<summary>CHECK (Cohort Hip and Cohort Knee) Dataset</summary>

[Link to dataset](https://easy.dans.knaw.nl/ui/datasets/id/easy-dataset:62955)

> Bijlsma, MD, PhD, Professor J.W.J. (University Medical Center Utrecht); Wesseling, PhD J. (University Medical Center Utrecht) (2015): CHECK (Cohort Hip & Cohort Knee) data of baseline (T0). DANS. https://doi.org/10.17026/dans-xs3-ws3s
</details>

## Citation

If you use our code or think our work is relevant to yours, we encourage you to cite our paper:

```bibtex
@article{molder2021materials,
    title = {Learning Medical Materials from Radiography Images},
    author = {Molder, Carson and Lowe, Benjamin and Zhan, Justin},
    journal = {Under review},
    year = {2021}
}
```
